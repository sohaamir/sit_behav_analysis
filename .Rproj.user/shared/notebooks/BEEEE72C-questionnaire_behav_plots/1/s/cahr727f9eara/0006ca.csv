"0","# Set significance threshold for analyses"
"0","SIGNIFICANCE_THRESHOLD <- 0.2"
"0",""
"0","################## SHARED UTILITY FUNCTIONS ###################"
"0",""
"0","theme_custom <- theme_minimal() +"
"0","  theme("
"0","    panel.grid.minor = element_blank(),"
"0","    legend.position = ""right"","
"0","    plot.title = element_text(size = 12, face = ""bold""),"
"0","    plot.subtitle = element_text(size = 10),"
"0","    axis.title = element_text(size = 10),"
"0","    legend.title = element_text(size = 10),"
"0","    legend.text = element_text(size = 9)"
"0","  )"
"0",""
"0","check_model_diagnostics <- function(model) {"
"0","  residuals <- residuals(model)"
"0","  fitted_vals <- fitted(model)"
"0","  "
"0","  shapiro_test <- shapiro.test(residuals)"
"0","  outliers <- boxplot.stats(residuals)$out"
"0","  vif_values <- car::vif(model)"
"0","  r2_values <- tryCatch({"
"0","    MuMIn::r.squaredGLMM(model)"
"0","  }, error = function(e) {"
"0","    c(NA, NA)"
"0","  })"
"0","  "
"0","  convergence <- !is.null(model@optinfo$conv$lme4$messages)"
"0","  homo_test <- cor.test(abs(residuals), fitted_vals)"
"0","  "
"0","  list("
"0","    residuals = list("
"0","      mean = mean(residuals),"
"0","      sd = sd(residuals),"
"0","      normality_p = shapiro_test$p.value"
"0","    ),"
"0","    model_fit = list("
"0","      r2_marginal = r2_values[1],"
"0","      r2_conditional = r2_values[2],"
"0","      aic = AIC(model),"
"0","      bic = BIC(model)"
"0","    ),"
"0","    assumptions = list("
"0","      vif = vif_values,"
"0","      homoscedasticity_cor = homo_test$estimate,"
"0","      homoscedasticity_p = homo_test$p.value,"
"0","      convergence = convergence"
"0","    ),"
"0","    outliers = list("
"0","      n_outliers = length(outliers),"
"0","      outlier_values = outliers"
"0","    )"
"0","  )"
"0","}"
"0",""
"0","################## DATA PROCESSING FUNCTIONS ###################"
"0",""
"0","process_initial_data <- function(data, outcome_type, group_2_2_in_with = FALSE) {"
"0","  base_data <- data %>%"
"0","    mutate("
"0","      consensus_group = case_when("
"0","        player.choice1_with == 0.5 ~ ifelse(group_2_2_in_with, ""2:2_with"", ""2:2_against""),"
"0","        player.choice1_with == 0 ~ ""4:0_against"","
"0","        player.choice1_with == 0.25 ~ ""3:1_against"","
"0","        player.choice1_with == 0.75 ~ ""3:1_with"","
"0","        player.choice1_with == 1 ~ ""4:0_with"""
"0","      ),"
"0","      consensus_level = case_when("
"0","        player.choice1_with %in% c(0, 1) ~ ""4:0"","
"0","        player.choice1_with %in% c(0.25, 0.75) ~ ""3:1"","
"0","        player.choice1_with == 0.5 ~ ""2:2"""
"0","      ),"
"0","      direction = if_else(player.choice1_with >= 0.5, ""With group"", ""Against group"")"
"0","    )"
"0","  "
"0","  outcome_data <- if(outcome_type == ""switch"") {"
"0","    base_data %>%"
"0","      group_by(participant.id_in_session, consensus_group, direction, gender) %>%"
"0","      summarise("
"0","        outcome_value = mean(player.switch_vs_stay) * 100,"
"0","        .groups = 'drop'"
"0","      )"
"0","  } else {"
"0","    base_data %>%"
"0","      mutate(bet_difference = player.bet2 - player.bet1) %>%"
"0","      group_by(participant.id_in_session, consensus_group, direction, gender) %>%"
"0","      summarise("
"0","        outcome_value = mean(bet_difference),"
"0","        .groups = 'drop'"
"0","      )"
"0","  }"
"0","  "
"0","  outcome_data %>%"
"0","    left_join("
"0","      base_data %>%"
"0","        group_by(participant.id_in_session) %>%"
"0","        slice(1) %>%"
"0","        select(participant.id_in_session, ssms, dass, lsas, srp_sf, ami, aq_10, age),"
"0","      by = ""participant.id_in_session"""
"0","    ) %>%"
"0","    mutate("
"0","      across(c(ssms, dass, lsas, srp_sf, ami, aq_10, age), scale),"
"0","      gender = factor(gender),"
"0","      consensus_group = factor(consensus_group, "
"0","                             levels = if(!group_2_2_in_with) "
"0","                               c(""2:2_against"", ""3:1_against"", ""4:0_against"", ""3:1_with"", ""4:0_with"")"
"0","                             else "
"0","                               c(""3:1_against"", ""4:0_against"", ""2:2_with"", ""3:1_with"", ""4:0_with""))"
"0","    )"
"0","}"
"0",""
"0","################## MODEL FUNCTIONS ###################"
"0",""
"0","run_questionnaire_models <- function(quest_var, data, outcome_type) {"
"0","  # Define models"
"0","  models <- list("
"0","    m1 = lmer(as.formula(paste(""outcome_value ~ consensus_group *"", quest_var, "
"0","                              ""+ age + (1|participant.id_in_session)"")),"
"0","              data = data,"
"0","              control = lmerControl(optimizer = ""bobyqa"")),"
"0","    "
"0","    m2 = lmer(as.formula(paste(""outcome_value ~ consensus_group *"", quest_var,"
"0","                              ""+ age + (1|participant.id_in_session) + (1|gender)"")),"
"0","              data = data,"
"0","              control = lmerControl(optimizer = ""bobyqa""))"
"0","  )"
"0","  "
"0","  # Compare models"
"0","  aic_values <- sapply(models, AIC)"
"0","  bic_values <- sapply(models, BIC)"
"0","  winning_idx <- which.min(aic_values)"
"0","  winning_model <- models[[winning_idx]]"
"0","  "
"0","  # Run diagnostics"
"0","  diagnostics <- check_model_diagnostics(winning_model)"
"0","  "
"0","  # Get ANOVA results"
"0","  model_anova <- car::Anova(winning_model, type = 2)"
"0","  interaction_term <- grep(paste0(""consensus_group:"", quest_var), rownames(model_anova), value = TRUE)"
"0","  interaction_p <- model_anova[interaction_term, ""Pr(>Chisq)""]"
"0","  "
"0","  list("
"0","    questionnaire = quest_var,"
"0","    models = models,"
"0","    winning_model = winning_model,"
"0","    aic_values = aic_values,"
"0","    bic_values = bic_values,"
"0","    winning_idx = winning_idx,"
"0","    p_value = interaction_p,"
"0","    diagnostics = diagnostics,"
"0","    anova_results = model_anova"
"0","  )"
"0","}"
"0",""
"0","################## PLOTTING FUNCTIONS ###################"
"0",""
"0","plot_continuous_relationship <- function(var, data, model_results, outcome_type) {"
"0","  data <- data %>%"
"0","    mutate("
"0","      consensus_level = case_when("
"0","        str_detect(consensus_group, ""4:0"") ~ ""4:0"","
"0","        str_detect(consensus_group, ""3:1"") ~ ""3:1"","
"0","        str_detect(consensus_group, ""2:2"") ~ ""2:2"""
"0","      ),"
"0","      consensus_level = factor(consensus_level, levels = c(""2:2"", ""3:1"", ""4:0""))"
"0","    )"
"0","  "
"0","  effects <- data %>%"
"0","    group_by(direction, consensus_level) %>%"
"0","    summarise("
"0","      correlation = cor(.data[[var]], outcome_value),"
"0","      .groups = 'drop'"
"0","    )"
"0","  "
"0","  y_lab <- if(outcome_type == ""switch"") {"
"0","    ""Choice switch probability (%)"""
"0","  } else {"
"0","    ""Bet difference (Bet 2 - Bet 1)"""
"0","  }"
"0","  "
"0","  p <- ggplot(data, "
"0","              aes(x = .data[[var]], "
"0","                  y = outcome_value,"
"0","                  color = direction)) +"
"0","    geom_point(alpha = 0.5) +"
"0","    geom_smooth(method = ""lm"", formula = y ~ x) +"
"0","    facet_wrap(~consensus_level) +"
"0","    labs(x = var,"
"0","         y = y_lab,"
"0","         title = paste(""Relationship between"", var, ""and"", ifelse(outcome_type == ""switch"", ""switch probability"", ""bet difference"")),"
"0","         subtitle = paste(""Raw p ="", format.pval(model_results$p_value[model_results$questionnaire == var], digits = 3),"
"0","                         ""\nFDR-adjusted p ="", format.pval(model_results$p_adjusted[model_results$questionnaire == var], digits = 3)),"
"0","         caption = paste(""Effect sizes (r) range:"", "
"0","                        round(min(effects$correlation), 3), ""to"","
"0","                        round(max(effects$correlation), 3))) +"
"0","    scale_color_manual(values = c(""Against group"" = ""red"", ""With group"" = ""blue"")) +"
"0","    theme_custom"
"0","  "
"0","  print(p)"
"0","}"
"0",""
"0","analyze_simple_slopes <- function(model, questionnaire_var, data, outcome_type, p_adjusted = NULL) {"
"0","  # Get the actual variable name used in the model formula"
"0","  model_vars <- all.vars(formula(model))"
"0","  actual_var_name <- model_vars[model_vars %in% c(""scale_name"", questionnaire_var)]"
"0","  "
"0","  # Calculate probe points using the original questionnaire variable name"
"0","  probe_points <- data %>%"
"0","    summarise("
"0","      low = mean(!!sym(questionnaire_var)) - sd(!!sym(questionnaire_var)),"
"0","      mean = mean(!!sym(questionnaire_var)),"
"0","      high = mean(!!sym(questionnaire_var)) + sd(!!sym(questionnaire_var))"
"0","    )"
"0","  "
"0","  # Create prediction data frame"
"0","  pred_data <- expand.grid("
"0","    consensus_group = levels(data$consensus_group),"
"0","    quest_score = c(probe_points$low, probe_points$mean, probe_points$high)"
"0","  ) %>%"
"0","    mutate("
"0","      quest_level = rep(c(""-1 SD"", ""Mean"", ""+1 SD""), "
"0","                       each = length(levels(data$consensus_group))),"
"0","      age = 0,"
"0","      participant.id_in_session = 1  # dummy value for random effect"
"0","    )"
"0","  "
"0","  # Use the actual variable name from the model"
"0","  pred_data[[actual_var_name]] <- pred_data$quest_score"
"0","  "
"0","  # Make predictions"
"0","  pred_data$predicted <- predict(model, newdata = pred_data, re.form = NA)"
"0","  "
"0","  # Get model statistics for subtitle"
"0","  model_stats <- car::Anova(model, type = 2)"
"0","  interaction_term <- grep(paste0(""consensus_group:"", questionnaire_var), "
"0","                         rownames(model_stats), value = TRUE)"
"0","  interaction_p <- model_stats[interaction_term, ""Pr(>Chisq)""]"
"0","  "
"0","  # Create plot..."
"0","  y_lab <- if(outcome_type == ""switch"") {"
"0","    ""Predicted Switch Probability (%)"""
"0","  } else {"
"0","    ""Predicted Bet Difference"""
"0","  }"
"0","  "
"0","  p <- ggplot(pred_data, "
"0","              aes(x = consensus_group, "
"0","                  y = predicted, "
"0","                  color = quest_level, "
"0","                  group = quest_level)) +"
"0","    geom_line() +"
"0","    geom_point(size = 3) +"
"0","    labs(title = paste(""Simple slopes analysis for"", questionnaire_var),"
"0","         subtitle = paste(""Raw p ="", format.pval(interaction_p, digits = 3),"
"0","                         if(!is.null(p_adjusted)) paste(""\nFDR-adjusted p ="", format.pval(p_adjusted, digits = 3)) else """"),"
"0","         x = ""Consensus Group"","
"0","         y = y_lab,"
"0","         color = paste(questionnaire_var, ""Level"")) +"
"0","    scale_color_manual(values = c(""red"", ""purple"", ""blue"")) +"
"0","    theme_custom"
"0","  "
"0","  list("
"0","    predictions = pred_data,"
"0","    plot = p,"
"0","    model_summary = summary(model),"
"0","    interaction_p = interaction_p"
"0","  )"
"0","}"
"0",""
"0","plot_moderation_effects <- function(model, data, original_scale_name, outcome_type, is_subscale = FALSE, p_adjusted = NULL) {"
"0","  # Create prediction grid at meaningful levels"
"0","  pred_data <- expand.grid("
"0","    consensus_group = levels(data$consensus_group),"
"0","    scale_name = seq(from = -2, to = 2, length.out = 100)  # Fine-grained scale scores"
"0","  )"
"0","  "
"0","  # Add mean age for predictions"
"0","  pred_data$age <- 0  # since age is scaled"
"0","  "
"0","  if(is_subscale) {"
"0","    subscale_patterns <- c(""_a$"", ""_d$"", ""_s$"", ""_p$"", ""_cd$"", ""_ia$"", "
"0","                          ""_ipm$"", ""_ca$"", ""_els$"", ""_ct$"", ""_es$"", ""_sm$"", ""_ba$"")"
"0","    subscale_cols <- grep(paste(subscale_patterns, collapse=""|""), "
"0","                         names(data), value=TRUE)"
"0","    for(col in subscale_cols) {"
"0","      if(col != original_scale_name) {"
"0","        pred_data[[col]] <- 0"
"0","      }"
"0","    }"
"0","    names(pred_data)[names(pred_data) == ""scale_name""] <- original_scale_name"
"0","  }"
"0","  "
"0","  # Get predictions"
"0","  pred_matrix <- predict(model, newdata = pred_data, re.form = NA, "
"0","                        allow.new.levels = TRUE)"
"0","  "
"0","  pred_data$predicted <- pred_matrix"
"0","  "
"0","  # Add direction information"
"0","  pred_data <- pred_data %>%"
"0","    mutate("
"0","      direction = case_when("
"0","        str_detect(consensus_group, ""with"") ~ ""With group"","
"0","        TRUE ~ ""Against group"""
"0","      ),"
"0","      consensus_level = case_when("
"0","        str_detect(consensus_group, ""4:0"") ~ ""4:0"","
"0","        str_detect(consensus_group, ""3:1"") ~ ""3:1"","
"0","        str_detect(consensus_group, ""2:2"") ~ ""2:2"""
"0","      ),"
"0","      consensus_level = factor(consensus_level, levels = c(""2:2"", ""3:1"", ""4:0""))"
"0","    )"
"0",""
"0","  # Get model statistics for subtitle"
"0","  model_stats <- car::Anova(model, type = 2)"
"0","  interaction_term <- if(is_subscale) {"
"0","    paste0(""consensus_group:"", original_scale_name)"
"0","  } else {"
"0","    ""consensus_group:scale_name"""
"0","  }"
"0","  interaction_p <- model_stats[interaction_term, ""Pr(>Chisq)""]"
"0","  "
"0","  # Get y-lab"
"0","  y_lab <- if(outcome_type == ""switch"") {"
"0","    ""Predicted choice switch probability (%)"""
"0","  } else {"
"0","    ""Predicted bet difference"""
"0","  }"
"0",""
"0","  # Create plot using original scale name"
"0","  p <- ggplot(pred_data, "
"0","              aes(x = if(is_subscale) .data[[original_scale_name]] else scale_name, "
"0","                  y = predicted, "
"0","                  color = direction)) +"
"0","    geom_line() +"
"0","    facet_wrap(~consensus_level) +"
"0","    labs(title = paste(""Moderation effect of"", original_scale_name),"
"0","         subtitle = paste(""Raw p ="", format.pval(interaction_p, digits = 3),"
"0","                         if(!is.null(p_adjusted)) paste(""\nFDR-adjusted p ="", format.pval(p_adjusted, digits = 3)) else """"),"
"0","         x = paste(original_scale_name, ""score (standardized)""),"
"0","         y = y_lab) +"
"0","    scale_color_manual(values = c(""Against group"" = ""red"", ""With group"" = ""blue"")) +"
"0","    theme_custom"
"0",""
"0","  print(p)"
"0","  "
"0","  return(list("
"0","    plot = p,"
"0","    predictions = pred_data,"
"0","    interaction_p = interaction_p"
"0","  ))"
"0","}"
"0",""
"0","create_median_split_plot <- function(summary_data, var, outcome_type, p_value, p_adjusted) {"
"0","  y_lab <- if(outcome_type == ""switch"") {"
"0","    ""Choice switch probability (%)"""
"0","  } else {"
"0","    ""Bet difference (Bet 2 - Bet 1)"""
"0","  }"
"0","  "
"0","  ggplot(summary_data, "
"0","         aes(x = consensus_level, "
"0","             y = mean_outcome, "
"0","             color = direction,"
"0","             linetype = quest_group,"
"0","             group = interaction(direction, quest_group))) +"
"0","    geom_line(size = 1) +"
"0","    geom_point(size = 3) +"
"0","    geom_errorbar(aes(ymin = mean_outcome - se, "
"0","                      ymax = mean_outcome + se), "
"0","                  width = 0.2) +"
"0","    scale_color_manual(values = c(""Against group"" = ""red"", ""With group"" = ""blue"")) +"
"0","    labs(x = ""Group consensus"","
"0","         y = y_lab,"
"0","         title = paste(""Effect of"", var, ""(Median-split)""),"
"0","         subtitle = paste(""Raw p ="", format.pval(p_value, digits = 3),"
"0","                         ""\nFDR-adjusted p ="", format.pval(p_adjusted, digits = 3))) +"
"0","    theme_custom"
"0","}"
"0",""
"0","################## MODERATION ANALYSIS ###################"
"0",""
"0","run_moderation_analysis <- function(data, scale_name, subscales = NULL, outcome_type, p_adjusted = NULL) {"
"0","  main_model <- lmer(outcome_value ~ consensus_group * scale_name + "
"0","                      age + (1|participant.id_in_session) + "
"0","                      (0 + scale_name|participant.id_in_session),"
"0","                    data = data,"
"0","                    control = lmerControl(optimizer = ""bobyqa""))"
"0","  "
"0","  main_r2 <- MuMIn::r.squaredGLMM(main_model)"
"0","  main_diagnostics <- check_model_diagnostics(main_model)"
"0","  main_plots <- plot_moderation_effects(main_model, data, scale_name, outcome_type, FALSE, p_adjusted)"
"0","  "
"0","  results <- list(main = list("
"0","    scale = scale_name,"
"0","    model = main_model,"
"0","    summary = summary(main_model),"
"0","    r2_marginal = main_r2[1],"
"0","    r2_conditional = main_r2[2],"
"0","    diagnostics = main_diagnostics,"
"0","    plots = main_plots"
"0","  ))"
"0","  "
"0","  if (!is.null(subscales)) {"
"0","    subscale_results <- map(subscales, function(subscale) {"
"0","      if(subscale %in% names(data)) {"
"0","        sub_model <- lmer(as.formula(paste("
"0","          ""outcome_value ~ consensus_group *"", subscale,"
"0","          ""+ age + (1|participant.id_in_session) + (0 +"", subscale, ""|participant.id_in_session)"""
"0","        )),"
"0","        data = data,"
"0","        control = lmerControl(optimizer = ""bobyqa""))"
"0","        "
"0","        sub_r2 <- MuMIn::r.squaredGLMM(sub_model)"
"0","        sub_diagnostics <- check_model_diagnostics(sub_model)"
"0","        "
"0","        list("
"0","          scale = subscale,"
"0","          model = sub_model,"
"0","          summary = summary(sub_model),"
"0","          r2_marginal = sub_r2[1],"
"0","          r2_conditional = sub_r2[2],"
"0","          diagnostics = sub_diagnostics"
"0","        )"
"0","      } else {"
"0","        NULL"
"0","      }"
"0","    })"
"0","    "
"0","    results$subscales <- compact(subscale_results)"
"0","  }"
"0","  "
"0","  return(results)"
"0","}"
"0",""
"0","check_moderation_assumptions <- function(model) {"
"0","  list("
"0","    vif = car::vif(model),"
"0","    normality = shapiro.test(residuals(model))$p.value,"
"0","    convergence = model@optinfo$conv$opt"
"0","  )"
"0","}"
"0",""
"0","################## RESULTS FORMATTING ###################"
"0",""
"0","format_results <- function(model_results, moderation_results, significant_vars, outcome_type) {"
"0","  output_text <- sprintf(""%s BY GROUP CONSENSUS - STATISTICAL ANALYSIS RESULTS\n\n"","
"0","                        ifelse(outcome_type == ""switch"", ""CHOICE SWITCH"", ""BET MAGNITUDE""))"
"0","  "
"0","  output_text <- paste0(output_text, ""Analysis run on: "", format(Sys.time(), ""%Y-%m-%d %H:%M:%S""), ""\n\n"")"
"0","  "
"0","  # For each questionnaire"
"0","  for(i in 1:nrow(model_results)) {"
"0","    quest_var <- model_results$questionnaire[i]"
"0","    diag <- model_results$diagnostics[[i]]"
"0","    "
"0","    output_text <- paste0(output_text, ""\n"", quest_var, "" ANALYSIS\n"","
"0","                         ""=================\n\n"","
"0","                         ""MODEL COMPARISON:\n"","
"0","                         ""================\n"")"
"0","    "
"0","    model_comp_df <- data.frame("
"0","      Model = 1:length(model_results$aic_values[[i]]),"
"0","      AIC = round(model_results$aic_values[[i]], 3),"
"0","      BIC = round(model_results$bic_values[[i]], 3),"
"0","      Is_Winner = ifelse(1:length(model_results$aic_values[[i]]) == model_results$winning_idx[i], ""Yes"", ""No"")"
"0","    )"
"0","    "
"0","    output_text <- paste0(output_text, "
"0","                         paste(capture.output(print.data.frame(model_comp_df)), collapse = ""\n""),"
"0","                         ""\n\nWINNING MODEL:\n"","
"0","                         ""==============\n"","
"0","                         ""R² marginal/conditional: "", round(diag$model_fit$r2_marginal, 3), ""/"", "
"0","                         round(diag$model_fit$r2_conditional, 3), ""\n"","
"0","                         ""Residual normality p: "", format.pval(diag$residuals$normality_p, digits = 3), ""\n"","
"0","                         ""VIF range: "", round(min(diag$assumptions$vif), 2), "" - "", round(max(diag$assumptions$vif), 2), ""\n"","
"0","                         ""Homoscedasticity: p = "", format.pval(diag$assumptions$homoscedasticity_p, digits = 3), ""\n"","
"0","                         ""Outliers: "", diag$outliers$n_outliers, ""\n\n"","
"0","                         ""ANOVA RESULTS:\n"","
"0","                         ""==============\n"","
"0","                         paste(capture.output(model_results$anova_results[[i]]), collapse = ""\n""),"
"0","                         ""\nRaw interaction p = "", format.pval(model_results$p_value[i], digits = 3),"
"0","                         ""\nFDR-adjusted interaction p = "", format.pval(model_results$p_adjusted[i], digits = 3), ""\n\n"")"
"0","  }"
"0","  "
"0","  # Add moderation results only for significant variables"
"0","  if(!is.null(moderation_results)) {"
"0","    output_text <- paste0(output_text, ""\nMODERATION ANALYSES:\n"","
"0","                         ""===================\n"")"
"0","    "
"0","    for(mod_result in moderation_results) {"
"0","      # Get p-values for main scale (using original FDR-adjusted p-value)"
"0","      main_anova <- car::Anova(mod_result$main$model, type = 2)"
"0","      interaction_term <- grep(""consensus_group:scale_name"", rownames(main_anova), value = TRUE)"
"0","      raw_p <- main_anova[interaction_term, ""Pr(>Chisq)""]"
"0","      # Get the corresponding FDR-adjusted p-value from initial analysis"
"0","      fdr_p <- model_results$p_adjusted[model_results$questionnaire == mod_result$main$scale]"
"0","      "
"0","      output_text <- paste0(output_text, ""\nScale: "", mod_result$main$scale, ""\n"","
"0","                           ""----------------------\n"","
"0","                           paste(capture.output(main_anova), collapse = ""\n""),"
"0","                           ""\nRaw interaction p = "", format.pval(raw_p, digits = 3),"
"0","                           ""\nFDR-adjusted interaction p = "", format.pval(fdr_p, digits = 3),"
"0","                           ""\n\nModel diagnostics: R² = "", round(mod_result$main$r2_marginal, 3),"
"0","                           "", Residual normality p = "", format.pval(mod_result$main$diagnostics$residuals$normality_p, digits = 3),"
"0","                           "", Outliers = "", mod_result$main$diagnostics$outliers$n_outliers, ""\n"")"
"0","      "
"0","      if(!is.null(mod_result$subscales)) {"
"0","        # Collect all subscale p-values first"
"0","        subscale_ps <- sapply(mod_result$subscales, function(sub_result) {"
"0","          sub_anova <- car::Anova(sub_result$model, type = 2)"
"0","          sub_interaction_term <- grep(paste0(""consensus_group:"", sub_result$scale), rownames(sub_anova), value = TRUE)"
"0","          sub_anova[sub_interaction_term, ""Pr(>Chisq)""]"
"0","        })"
"0","        "
"0","        # FDR correct all subscale p-values together"
"0","        subscale_ps_adjusted <- p.adjust(subscale_ps, method = ""fdr"")"
"0","        "
"0","        # Now output results for each subscale"
"0","        for(j in seq_along(mod_result$subscales)) {"
"0","          sub_result <- mod_result$subscales[[j]]"
"0","          sub_anova <- car::Anova(sub_result$model, type = 2)"
"0","          sub_interaction_term <- grep(paste0(""consensus_group:"", sub_result$scale), rownames(sub_anova), value = TRUE)"
"0","          sub_raw_p <- sub_anova[sub_interaction_term, ""Pr(>Chisq)""]"
"0","          "
"0","          output_text <- paste0(output_text, ""\nSubscale: "", sub_result$scale, ""\n"","
"0","                               paste(capture.output(sub_anova), collapse = ""\n""),"
"0","                               ""\nRaw interaction p = "", format.pval(sub_raw_p, digits = 3),"
"0","                               ""\nFDR-adjusted interaction p = "", format.pval(subscale_ps_adjusted[j], digits = 3),"
"0","                               ""\nModel diagnostics: R² = "", round(sub_result$r2_marginal, 3),"
"0","                               "", Residual normality p = "", format.pval(sub_result$diagnostics$residuals$normality_p, digits = 3),"
"0","                               "", Outliers = "", sub_result$diagnostics$outliers$n_outliers, ""\n"")"
"0","        }"
"0","      }"
"0","    }"
"0","  }"
"0","  "
"0","  return(output_text)"
"0","}"
"0",""
"0","################## MAIN ANALYSIS FUNCTION ###################"
"0",""
"0","run_analysis <- function(outcome_type) {"
"0"," # Read data"
"0"," merged_data <- read_csv(here(""data"", ""preprocessed"", ""merged_test_data.csv""), show_col_types = FALSE)"
"0"," "
"0"," # Process data"
"0"," processed_data <- process_initial_data(merged_data, outcome_type, FALSE)"
"0"," processed_data_alt <- process_initial_data(merged_data, outcome_type, TRUE)"
"0"," "
"0"," # Define questionnaire variables"
"0"," questionnaire_vars <- c(""ssms"", ""dass"", ""lsas"", ""srp_sf"", ""ami"", ""aq_10"")"
"0"," "
"0"," # Run models for all questionnaires with enhanced diagnostics"
"0"," model_results <- map_df(questionnaire_vars, function(var) {"
"0","   result_primary <- run_questionnaire_models(var, processed_data, outcome_type)"
"0","   result_alt <- run_questionnaire_models(var, processed_data_alt, outcome_type)"
"0","   "
"0","   tibble("
"0","     questionnaire = result_primary$questionnaire,"
"0","     p_value = result_primary$p_value,"
"0","     alt_p_value = result_alt$p_value,"
"0","     aic_values = list(result_primary$aic_values),"
"0","     bic_values = list(result_primary$bic_values),"
"0","     winning_idx = result_primary$winning_idx,"
"0","     model = list(result_primary$winning_model),"
"0","     diagnostics = list(result_primary$diagnostics),"
"0","     anova_results = list(result_primary$anova_results)"
"0","   )"
"0"," })"
"0"," "
"0"," # Add FDR-adjusted p-values"
"0"," model_results$p_adjusted <- p.adjust(model_results$p_value, method = ""fdr"")"
"0"," "
"0"," # Identify significant results"
"0"," significant_vars <- model_results %>%"
"0","   filter(p_adjusted < SIGNIFICANCE_THRESHOLD) %>%"
"0","   pull(questionnaire)"
"0"," "
"0"," cat(""\nVariables passing significance threshold (p_adjusted <"", SIGNIFICANCE_THRESHOLD, ""):"", "
"0","     ifelse(length(significant_vars) > 0, paste(significant_vars, collapse = "", ""), ""none""), ""\n"")"
"0"," "
"0"," # Create continuous relationship plots"
"0"," for(var in questionnaire_vars) {"
"0","   plot_continuous_relationship(var, processed_data, model_results, outcome_type)"
"0"," }"
"0"," "
"0"," # Define subscale mapping"
"0"," subscale_mapping <- list("
"0","   lsas = c(""lsas_p"", ""lsas_s""),"
"0","   dass = c(""dass_a"", ""dass_d"", ""dass_s""),"
"0","   ssms = c(""ssms_cd"", ""ssms_ia""),"
"0","   srp_sf = c(""srp_sf_ipm"", ""srp_sf_ca"", ""srp_sf_els"", ""srp_sf_ct""),"
"0","   ami = c(""ami_es"", ""ami_sm"", ""ami_ba""),"
"0","   aq_10 = NULL"
"0"," )"
"0"," "
"0"," if(length(significant_vars) > 0) {"
"0","   # Process subscale data"
"0","   subscale_data <- merged_data %>%"
"0","     group_by(participant.id_in_session) %>%"
"0","     slice(1) %>%"
"0","     select(participant.id_in_session,"
"0","            lsas_p, lsas_s,"
"0","            dass_a, dass_d, dass_s,"
"0","            ssms_cd, ssms_ia,"
"0","            srp_sf_ipm, srp_sf_ca, srp_sf_els, srp_sf_ct,"
"0","            ami_es, ami_sm, ami_ba)"
"0","   "
"0","   subscale_data_scaled <- subscale_data %>%"
"0","     ungroup() %>%"
"0","     mutate(across(-participant.id_in_session, ~as.vector(scale(.x))))"
"0","   "
"0","   processed_data_with_subscales <- processed_data %>%"
"0","     left_join(subscale_data_scaled, by = ""participant.id_in_session"")"
"0","   "
"0","   # Run moderation analyses with enhanced diagnostics"
"0","   moderation_results <- map(significant_vars, function(scale) {"
"0","     subscales <- subscale_mapping[[scale]]"
"0","     "
"0","     mod_data <- processed_data_with_subscales %>%"
"0","       rename(scale_name = !!scale)"
"0","     "
"0","     p_adjusted <- model_results$p_adjusted[model_results$questionnaire == scale]"
"0","     "
"0","     results <- run_moderation_analysis(mod_data, scale, subscales, outcome_type, p_adjusted)"
"0","     "
"0","     # Add diagnostics to moderation results"
"0","     results$main$diagnostics <- check_model_diagnostics(results$main$model)"
"0","     "
"0","     # Add diagnostics for subscales if they exist"
"0","     if(!is.null(results$subscales)) {"
"0","       results$subscales <- map(results$subscales, function(sub_result) {"
"0","         sub_result$diagnostics <- check_model_diagnostics(sub_result$model)"
"0","         sub_result"
"0","       })"
"0","     }"
"0","     "
"0","     # Run simple slopes analyses with diagnostics"
"0","     slopes_analysis <- analyze_simple_slopes("
"0","       model = results$main$model,"
"0","       questionnaire_var = scale,"
"0","       data = processed_data,"
"0","       outcome_type = outcome_type,"
"0","       p_adjusted = p_adjusted"
"0","     )"
"0","     "
"0","     # Store slopes analysis "
"0","     results$slopes_analysis <- slopes_analysis"
"0","     "
"0","     results"
"0","   })"
"0","   "
"0","   # Create median-split plots and analyses for significant results"
"0","   for(var in significant_vars) {"
"0","     summary_data <- processed_data %>%"
"0","       mutate("
"0","         consensus_level = case_when("
"0","           str_detect(consensus_group, ""4:0"") ~ ""4:0"","
"0","           str_detect(consensus_group, ""3:1"") ~ ""3:1"","
"0","           str_detect(consensus_group, ""2:2"") ~ ""2:2"""
"0","         ),"
"0","         consensus_level = factor(consensus_level, levels = c(""2:2"", ""3:1"", ""4:0"")),"
"0","         quest_group = ifelse(.data[[var]] > median(.data[[var]]), ""High"", ""Low"")"
"0","       ) %>%"
"0","       group_by(consensus_level, direction, quest_group) %>%"
"0","       summarise("
"0","         mean_outcome = mean(outcome_value),"
"0","         se = sd(outcome_value) / sqrt(n()),"
"0","         .groups = 'drop'"
"0","       )"
"0","     "
"0","     p_median <- create_median_split_plot(summary_data, var, outcome_type, "
"0","                                        model_results$p_value[model_results$questionnaire == var],"
"0","                                        model_results$p_adjusted[model_results$questionnaire == var])"
"0","     print(p_median)"
"0","     "
"0","     model <- model_results$model[[which(model_results$questionnaire == var)]]"
"0","     if(!is.null(model)) {"
"0","       slopes_analysis <- analyze_simple_slopes("
"0","         model,"
"0","         var,"
"0","         processed_data,"
"0","         outcome_type,"
"0","         p_adjusted = model_results$p_adjusted[model_results$questionnaire == var]"
"0","       )"
"0","       print(slopes_analysis$plot)"
"0","     }"
"0","   }"
"0"," }"
"0"," "
"0"," # Generate and save results with enhanced diagnostics"
"0"," results_text <- format_results("
"0","   model_results, "
"0","   if(length(significant_vars) > 0) moderation_results else NULL, "
"0","   significant_vars, "
"0","   outcome_type"
"0"," )"
"0"," "
"0"," # Create output directory and file"
"0"," dir.create(here(""output"", ""behav"", ""questionnaire""), showWarnings = FALSE, recursive = TRUE)"
"0"," output_file <- here("
"0","   ""output"", "
"0","   ""behav"","
"0","   ""questionnaire"","
"0","   ifelse("
"0","     outcome_type == ""switch"","
"0","     ""choice_switching_by_group_consensus.txt"","
"0","     ""bet_difference_by_group_consensus.txt"""
"0","   )"
"0"," )"
"0"," "
"0"," writeLines(results_text, output_file)"
"0"," cat(""\nResults written to:"", output_file, ""\n"")"
"0"," "
"0"," return(list("
"0","   model_results = model_results,"
"0","   significant_vars = significant_vars,"
"0","   processed_data = processed_data,"
"0","   moderation_results = if(length(significant_vars) > 0) moderation_results else NULL,"
"0","   diagnostics_summary = map(model_results$diagnostics, ~list("
"0","     residuals = .$residuals,"
"0","     model_fit = .$model_fit,"
"0","     assumptions = .$assumptions,"
"0","     outliers = .$outliers"
"0","   ))"
"0"," ))"
"0","}"
"0",""
"0","################## RUN ANALYSES ###################"
"0",""
"0","# Run analyses for both outcomes"
"0","switch_results <- run_analysis(""switch"")"
"2","boundary (singular) fit: see help('isSingular')
"
"2","boundary (singular) fit: see help('isSingular')
"
"2","boundary (singular) fit: see help('isSingular')
"
"2","boundary (singular) fit: see help('isSingular')
"
"2","boundary (singular) fit: see help('isSingular')
"
"2","boundary (singular) fit: see help('isSingular')
"
"2","boundary (singular) fit: see help('isSingular')
"
"2","boundary (singular) fit: see help('isSingular')
"
"2","boundary (singular) fit: see help('isSingular')
"
"2","boundary (singular) fit: see help('isSingular')
"
"2","boundary (singular) fit: see help('isSingular')
"
"2","boundary (singular) fit: see help('isSingular')
"
"2","boundary (singular) fit: see help('isSingular')
"
"2","boundary (singular) fit: see help('isSingular')
"
"2","boundary (singular) fit: see help('isSingular')
"
"2","boundary (singular) fit: see help('isSingular')
"
"2","boundary (singular) fit: see help('isSingular')
"
"2","boundary (singular) fit: see help('isSingular')
"
"2","boundary (singular) fit: see help('isSingular')
"
"2","boundary (singular) fit: see help('isSingular')
"
"2","boundary (singular) fit: see help('isSingular')
"
"2","boundary (singular) fit: see help('isSingular')
"
"2","boundary (singular) fit: see help('isSingular')
"
"2","boundary (singular) fit: see help('isSingular')
"
"1","
Variables passing significance threshold (p_adjusted <"
"1"," "
"1","0.2"
"1"," "
"1","):"
"1"," "
"1","ssms, dass, lsas, srp_sf, ami, aq_10"
"1"," "
"1","
"
"1","
Results written to:"
"1"," "
"1","/Users/aamirsohail/University of Birmingham - ALPN Laboratory - Research - Projects/online_social_study/otree_projects/test_analysis/output/behav/questionnaire/choice_switching_by_group_consensus.txt"
"1"," "
"1","
"
